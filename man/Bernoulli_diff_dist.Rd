% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DifferenceDistribution.R
\name{Bernoulli_diff_dist}
\alias{Bernoulli_diff_dist}
\title{Compute the distribution of differences of replacement samples of two Bernoulli experiments.}
\usage{
Bernoulli_diff_dist(nA, kA, nB, kB)
}
\arguments{
\item{nA}{number of A experiments.}

\item{kA}{number of A successes observed.}

\item{nB}{number of B experiments.}

\item{kB}{number of B successes observed.}
}
\value{
experiment summaries
}
\description{
Compute the distribution of \code{max(1, nBeffective/nAeffective)*sum(a) - max*1, nAeffective/nBeffective)*sum(b)}
where \code{a} is a 0/1 vector of length \code{nAeffective} with each item 1 with independent probability \code{(kA+kB)/(nA+nB)},
and \code{b} is a 0/1 vector of length \code{nBeffective} with each item 1 with independent probability \code{(kA+kB)/(nA+nB)}.
The idea is: under this scaling differnces in success rates between the two processes are easilly observed as differences
in counts returned by the scaled processes.
The method be used to get the exact probability of a given difference under the null hypothesis that
both the A and B processes have the same success rate.
}
\details{
Note the intent that we are measuring the results of an A/B test with \code{nA \%\% nB == 0}
(no padding needed),  or  \code{nA >> nB}, or \code{nB >> nA}. The larger sample is padded so
the smaller sample divides evenly into it (allowing faster calculation methods).  The sizes of the
effective samples are given by \code{nAeffective} and \code{nBeffective}.  The padding will
slighly over-estimate confidences due the increased sample size, but if \code{nA} and \code{nB} are
not near each other- this will be a small effect.
}
\examples{

res <- Bernoulli_diff_dist(5000, 2000, 200, 100)
res$distribution[res$distribution$diff==ceiling(res$effective_diff), ]$prob_le
# above is the chance of a-b being at least as small (b being at least that
# much better) as observed if the two samples were drawn from a pooled process with
# no actual rate difference.
# That can work as a significance of a 1-sided test.
# two sided:
res$distribution[res$distribution$diff==ceiling(res$effective_diff), ]$prob_le +
   res$distribution[res$distribution$diff==floor(-res$effective_diff), ]$prob_ge

}
